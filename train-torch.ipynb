{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Joseph Ko <br>\n",
    "Reproducible notebook to train pytorch models from: 'A Machine Learning Framework for Predicting Microphysical Properties of Ice Crystals from Cloud Particle Imagery' (Ko et al. 2025) <br>\n",
    "Required packages: see torch.yaml file for required files\n",
    "Models were trained using NVIDIA a100 GPUs. Package configurations may vary depending on the GPU you use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86477af-3c28-415d-a7e9-6bd3bddaa708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import torchvision.transforms as T\n",
    "import json\n",
    "# Add your project root to sys.path for imports \n",
    "# (models and data modules should be in this directory)\n",
    "sys.path.append('/home/jko/ice3d')\n",
    "# Import your models and datamodules\n",
    "from models.mlp_regression import MLPRegression\n",
    "from models.mlp_classification import MLPClassification\n",
    "from models.cnn_regression import VanillaCNNRegression\n",
    "from models.cnn_classification import VanillaCNNClassification\n",
    "from models.resnet18_regression import ResNet18Regression\n",
    "from models.resnet18_classification import ResNet18Classification\n",
    "from data.single_view_datamodule import SingleViewDataModule\n",
    "from data.stereo_view_datamodule import StereoViewDataModule\n",
    "from data.tabular_datamodule import TabularDataModule\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General configurations and global paths\n",
    "targets_reg = 'rho_eff,sa_eff' # regression targets\n",
    "targets_cls = 'n_arms' # classification targets\n",
    "tabular_root = '/home/jko/synth-ros-data/tabular-data-v2/shuffled_small'\n",
    "h5_root = '/home/jko/synth-ros-data/imgs-ml-ready/shuffled_small'\n",
    "tabular_path = os.path.join(tabular_root, 'ros-tabular-data-shuffled-default-subset-700000.parquet')\n",
    "tabular_2ds_path = os.path.join(tabular_root, 'ros-tabular-data-stereo-default-2ds-shuffled-subset-700000.parquet')\n",
    "tabular_phips_path = os.path.join(tabular_root, 'ros-tabular-data-stereo-default-phips-shuffled-subset-700000.parquet')\n",
    "h5_default_path = os.path.join(h5_root, 'default_shuffled_small.h5')\n",
    "h5_2ds_path = os.path.join(h5_root, '2ds_shuffled_small.h5')\n",
    "h5_phips_path = os.path.join(h5_root, 'phips_shuffled_small.h5')\n",
    "log_dir = './lightning_logs'\n",
    "feature_names='aspect_ratio,aspect_ratio_elip,extreme_pts,contour_area,contour_perimeter,area_ratio,complexity,circularity'\n",
    "train_idx='/home/jko/synth-ros-data/idx/idx-train-sequential-subset-700k.txt'\n",
    "val_idx='/home/jko/synth-ros-data/idx/idx-val-sequential-subset-700k.txt'\n",
    "test_idx='/home/jko/synth-ros-data/idx/idx-test-sequential-subset-700k.txt'\n",
    "class_to_idx_json='/home/jko/ice3d/data/class_to_idx.json'\n",
    "n_rand = 666 # random seed\n",
    "num_gpus = 1 # set to 1 to prevent issues with multi-gpu training in jupyter environment\n",
    "ncpus = 32 # number of cpus available\n",
    "prefetch_factor = int(ncpus/2)\n",
    "subset_size = 0.1 # set to 10% to speed up training for demonstration purposes\n",
    "batch_size=128\n",
    "lr=1e-3\n",
    "max_epochs=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-configure argument lists for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store args of each model in a dictionary\n",
    "args_dict = {} # initialize\n",
    "\n",
    "# MLP, Regression\n",
    "args_dict['mlp_reg'] = SimpleNamespace(\n",
    "    model='mlp_regression',\n",
    "    data_type='tabular',\n",
    "    tabular_file=tabular_path,\n",
    "    targets=targets_reg,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='regression',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='mlp-reg-tb',\n",
    "    csv_log_name='mlp-reg-csv',\n",
    "    feature_names=feature_names,\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=None\n",
    ")\n",
    "# MLP, Classification\n",
    "args_dict['mlp_cls'] = SimpleNamespace(\n",
    "    model='mlp_regression',\n",
    "    data_type='tabular',\n",
    "    tabular_file=tabular_path,\n",
    "    targets=targets_cls,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='regression',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='mlp-cls-tb',\n",
    "    csv_log_name='mlp-cls-csv',\n",
    "    class_to_idx_json=class_to_idx_json,\n",
    "    feature_names=feature_names,\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx\n",
    ")\n",
    "# CNN, Regression\n",
    "args_dict['cnn_reg'] = SimpleNamespace(\n",
    "    model='cnn_regression',\n",
    "    data_type='single_view_h5',\n",
    "    hdf_file=h5_default_path,\n",
    "    targets=targets_reg,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='regression',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='cnn-reg-tb',\n",
    "    csv_log_name='cnn-reg-csv',\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=None,\n",
    "    input_channels=1\n",
    ")\n",
    "# CNN, Classification\n",
    "args_dict['cnn_cls'] = SimpleNamespace(\n",
    "    model='cnn_classification',\n",
    "    data_type='single_view_h5',\n",
    "    hdf_file=h5_default_path,\n",
    "    targets=targets_cls,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='classification',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='cnn-cls-tb',\n",
    "    csv_log_name='cnn-cls-csv',\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=class_to_idx_json,\n",
    "    input_channels=1\n",
    ")\n",
    "# ResNet-18, Regression, Singlve View\n",
    "args_dict['resnet18_reg'] = SimpleNamespace(\n",
    "    model='resnet18_regression',\n",
    "    data_type='single_view_h5',\n",
    "    hdf_file=h5_default_path,\n",
    "    targets=targets_reg,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='regression',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='rn18-reg-tb',\n",
    "    csv_log_name='rn18-reg-csv',\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=None,\n",
    "    input_channels=1\n",
    ")\n",
    "# ResNet-18, Regression, Stereo, 2DS\n",
    "args_dict['resnet18_reg_stereo_2ds'] = SimpleNamespace(\n",
    "    model='resnet18_regression',\n",
    "    data_type='stereo_view_h5',\n",
    "    hdf_file_left=h5_default_path,\n",
    "    hdf_file_right=h5_2ds_path,\n",
    "    targets=targets_reg,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='regression',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='rn18-reg-stereo-2ds-tb',\n",
    "    csv_log_name='rn18-reg-stereo-2ds-csv',\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=None,\n",
    "    input_channels=2\n",
    ")\n",
    "# ResNet-18, Regression, Stereo, PHIPS\n",
    "args_dict['resnet18_reg_stereo_phips'] = SimpleNamespace(\n",
    "    model='resnet18_regression',\n",
    "    data_type='stereo_view_h5',\n",
    "    hdf_file_left=h5_default_path,\n",
    "    hdf_file_right=h5_phips_path,\n",
    "    targets=targets_reg,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='regression',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='rn18-reg-stereo-phips-tb',\n",
    "    csv_log_name='rn18-reg-stereo-phips-csv',\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=None,\n",
    "    input_channels=2\n",
    ")\n",
    "# ResNet-18, Classification, Single View\n",
    "args_dict['resnet18_cls'] = SimpleNamespace(\n",
    "    model='resnet18_classification',\n",
    "    data_type='single_view_h5',\n",
    "    hdf_file=h5_default_path,\n",
    "    targets=targets_cls,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='classification',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='rn18-cls-tb',\n",
    "    csv_log_name='rn18-cls-csv',\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=class_to_idx_json,\n",
    "    input_channels=1\n",
    ")\n",
    "# ResNet-18, Classification, Stereo, 2DS\n",
    "args_dict['resnet18_cls_stereo_2ds'] = SimpleNamespace(\n",
    "    model='resnet18_classification',\n",
    "    data_type='stereo_view_h5',\n",
    "    hdf_file_left=h5_default_path,\n",
    "    hdf_file_right=h5_2ds_path,\n",
    "    targets=targets_cls,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='classification',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='rn18-cls-stereo-2ds-tb',\n",
    "    csv_log_name='rn18-cls-stereo-2ds-csv',\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=class_to_idx_json,\n",
    "    input_channels=2\n",
    ")\n",
    "# ResNet-18, Classification, Stereo, PHIPS\n",
    "args_dict['resnet18_cls_stereo_phips'] = SimpleNamespace(\n",
    "    model='resnet18_classification',\n",
    "    data_type='stereo_view_h5',\n",
    "    hdf_file_left=h5_default_path,\n",
    "    hdf_file_right=h5_phips_path,\n",
    "    targets=targets_cls,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    max_epochs=max_epochs,\n",
    "    subset_size=subset_size,\n",
    "    seed=n_rand,\n",
    "    num_workers=ncpus,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    task_type='classification',\n",
    "    log_dir=log_dir,\n",
    "    tb_log_name='rn18-cls-stereo-phips-tb',\n",
    "    csv_log_name='rn18-cls-stereo-phips-csv',\n",
    "    num_gpus=num_gpus,\n",
    "    train_idx=train_idx,\n",
    "    val_idx=val_idx,\n",
    "    test_idx=test_idx,\n",
    "    class_to_idx_json=class_to_idx_json,\n",
    "    input_channels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args, input_size=None, output_size=None, num_classes=None):\n",
    "    if args.model == 'mlp_regression':\n",
    "        return MLPRegression(input_size, output_size, learning_rate=args.lr)\n",
    "    elif args.model == 'mlp_classification':\n",
    "        return MLPClassification(input_size, num_classes, learning_rate=args.lr)\n",
    "    elif args.model == 'cnn_regression':\n",
    "        return VanillaCNNRegression(input_channels=args.input_channels, output_size=output_size, learning_rate=args.lr)\n",
    "    elif args.model == 'cnn_classification':\n",
    "        return VanillaCNNClassification(input_channels=args.input_channels, num_classes=num_classes, learning_rate=args.lr)\n",
    "    elif args.model == 'resnet18_regression':\n",
    "        return ResNet18Regression(input_channels=args.input_channels, output_size=output_size, learning_rate=args.lr)\n",
    "    elif args.model == 'resnet18_classification':\n",
    "        return ResNet18Classification(input_channels=args.input_channels, num_classes=num_classes, learning_rate=args.lr)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown model type: {args.model}')\n",
    "\n",
    "def get_transforms(args):\n",
    "    transforms = {}\n",
    "    # Define transforms based on data_type\n",
    "    if args.data_type in ['single_view_h5', 'stereo_view_h5']:\n",
    "        train_transform = T.Compose([\n",
    "                T.RandomHorizontalFlip(),\n",
    "                T.RandomVerticalFlip(),\n",
    "                T.Normalize(mean=[0.5] * args.input_channels, std=[1.0] * args.input_channels)\n",
    "            ])\n",
    "        val_transform = T.Compose([\n",
    "                T.Normalize(mean=[0.5] * args.input_channels, std=[1.0] * args.input_channels)\n",
    "            ])\n",
    "        transforms['train'] = train_transform\n",
    "        transforms['val'] = val_transform\n",
    "        transforms['test'] = val_transform\n",
    "        # define target transform\n",
    "        if args.task_type == 'classification':\n",
    "            target_transform = None\n",
    "        else:\n",
    "            def log_transform(x):\n",
    "                return torch.log(x)\n",
    "            target_transform = log_transform\n",
    "        transforms['train_target'] = target_transform\n",
    "        transforms['val_target'] = target_transform\n",
    "        transforms['test_target'] = target_transform    \n",
    "        return transforms\n",
    "    elif args.data_type == 'tabular':\n",
    "        # define target transform\n",
    "        if args.task_type == 'classification':\n",
    "            target_transform = None\n",
    "        else:\n",
    "            def log_transform(x):\n",
    "                return torch.log(x)\n",
    "            target_transform = log_transform\n",
    "        transforms['target'] = target_transform\n",
    "        return transforms\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_datamodule(args, class_to_idx=None):\n",
    "    transforms = get_transforms(args)\n",
    "    if args.data_type == 'single_view_h5':\n",
    "        return SingleViewDataModule(\n",
    "            hdf_file=args.hdf_file,\n",
    "            target_names=args.targets.split(','),\n",
    "            train_idx=None,\n",
    "            val_idx=None,\n",
    "            test_idx=None,\n",
    "            batch_size=args.batch_size,\n",
    "            subset_size=args.subset_size,\n",
    "            subset_seed=args.seed,\n",
    "            num_workers=args.num_workers,\n",
    "            prefetch_factor=args.prefetch_factor,\n",
    "            train_transform=transforms['train'],\n",
    "            val_transform=transforms['val'],\n",
    "            test_transform=transforms['test'],\n",
    "            train_target_transform=transforms['train_target'],\n",
    "            val_target_transform=transforms['val_target'],\n",
    "            test_target_transform=transforms['test_target'],\n",
    "            task_type=args.task_type,\n",
    "            class_to_idx=class_to_idx\n",
    "        )\n",
    "    elif args.data_type == 'stereo_view_h5':\n",
    "        return StereoViewDataModule(\n",
    "            hdf_file_left=args.hdf_file_left,\n",
    "            hdf_file_right=args.hdf_file_right,\n",
    "            target_names=args.targets.split(','),\n",
    "            train_idx=None,\n",
    "            val_idx=None,\n",
    "            test_idx=None,\n",
    "            batch_size=args.batch_size,\n",
    "            subset_size=args.subset_size,\n",
    "            subset_seed=args.seed,\n",
    "            num_workers=args.num_workers,\n",
    "            prefetch_factor=args.prefetch_factor,\n",
    "            train_transform=transforms['train'],\n",
    "            val_transform=transforms['val'],\n",
    "            test_transform=transforms['test'],\n",
    "            train_target_transform=transforms['train_target'],\n",
    "            val_target_transform=transforms['val_target'],\n",
    "            test_target_transform=transforms['test_target'],\n",
    "            task_type=args.task_type,\n",
    "            class_to_idx=class_to_idx\n",
    "        )\n",
    "    elif args.data_type == 'tabular':\n",
    "        feature_names = args.feature_names.split(',') if args.feature_names else None\n",
    "        return TabularDataModule(\n",
    "            data_file=args.tabular_file,\n",
    "            feature_names=feature_names,\n",
    "            target_names=args.targets.split(','),\n",
    "            batch_size=args.batch_size,\n",
    "            subset_size=args.subset_size,\n",
    "            subset_seed=args.seed,\n",
    "            num_workers=args.num_workers,\n",
    "            task_type=args.task_type,\n",
    "            class_to_idx=class_to_idx,\n",
    "            target_transform=transforms['target'],\n",
    "            train_idx=args.train_idx,\n",
    "            val_idx=args.val_idx,   \n",
    "            test_idx=args.test_idx\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Unknown data type: {args.data_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params | Mode \n",
      "----------------------------------------\n",
      "0 | fc1  | Linear | 1.2 K  | train\n",
      "1 | fc2  | Linear | 8.3 K  | train\n",
      "2 | fc3  | Linear | 2.1 K  | train\n",
      "3 | fc4  | Linear | 66     | train\n",
      "----------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a917f92baa144ec918bf4d40fb9fba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4744dd38e06492c9825c28f767bff70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855a3cb2427f425189da73b66682cbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035b3a71855e403293e9043a1d1131f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5c92791c414ed5b9ada3a566ea30f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd30cf8385dc44219826ce55f78d15e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c3f4f17b88420cb88d4fa7056f6ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['mlp_reg']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params | Mode \n",
      "----------------------------------------\n",
      "0 | fc1  | Linear | 1.2 K  | train\n",
      "1 | fc2  | Linear | 8.3 K  | train\n",
      "2 | fc3  | Linear | 2.1 K  | train\n",
      "3 | fc4  | Linear | 33     | train\n",
      "----------------------------------------\n",
      "11.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4141cb0047cf4c4da5c8d39d7c5e2728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babbf5accea543fa8013789c62da4297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f3918dc2b64f078b9e66d22f1a9a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305189382db648378c70a703dcee8c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e5b86951c4408ea46c5baecab36e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3b5c1dddcb4c29a149db8caf4f6c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931d645c6a40436e9fbdaf6b2f4b5945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['mlp_cls']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | conv1 | Conv2d    | 160    | train\n",
      "1 | conv2 | Conv2d    | 4.6 K  | train\n",
      "2 | conv3 | Conv2d    | 18.5 K | train\n",
      "3 | pool  | MaxPool2d | 0      | train\n",
      "4 | fc1   | Linear    | 6.4 M  | train\n",
      "5 | fc2   | Linear    | 8.3 K  | train\n",
      "6 | fc3   | Linear    | 130    | train\n",
      "--------------------------------------------\n",
      "6.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 M     Total params\n",
      "25.817    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff7dd2e38934c9086087e56fed2c7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b9178ec9514da88c6508d45c37f311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e476138924b94e0a84756f43e6289109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92906b6da2004c0fa8557c7ed36bae57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f804fbbce2374c5f921609dccfcb946e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dba995bacb34f28a725a43d68207ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2856c8955b6046578627dc5d2ee40be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['cnn_reg']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | conv1 | Conv2d    | 160    | train\n",
      "1 | conv2 | Conv2d    | 4.6 K  | train\n",
      "2 | conv3 | Conv2d    | 18.5 K | train\n",
      "3 | pool  | MaxPool2d | 0      | train\n",
      "4 | fc1   | Linear    | 6.4 M  | train\n",
      "5 | fc2   | Linear    | 8.3 K  | train\n",
      "6 | fc3   | Linear    | 455    | train\n",
      "--------------------------------------------\n",
      "6.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 M     Total params\n",
      "25.819    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a33b959d1e04df9bc9d0cefaac683cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420e03dce5fd49fead610d027d2b473e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baff43bdacdc47ad8c2e24bdcc243675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0127ce63d6848878eea7b5622f389ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b9617067ef4e38a89469b37b4859bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ae2e4af5d34411a07bfeb033c0a479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a40fa429aa34b858d36583b93bf5e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['cnn_cls']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression, Single View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type   | Params | Mode \n",
      "------------------------------------------\n",
      "0 | resnet | ResNet | 11.2 M | train\n",
      "------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.685    Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0500ec845c49c590a81ec7d93fb333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d24723552f4fd48300a676c145771c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e7da2840a34951b63e113d48f0b293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05210a89caf4f37aca4406da22ea0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0839eda31e0f4f2481f9069114d87d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0cab5c0df8458282caee8c58538bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f9359f76ed4800a06bb8f256a835a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['resnet18_reg']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression, Stereo, 2DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type   | Params | Mode \n",
      "------------------------------------------\n",
      "0 | resnet | ResNet | 11.2 M | train\n",
      "------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.698    Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f667e02cc5d54c26b90f962ff03ce0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714068db478e4c958a1f240afe65c766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdca418757dd406ab5e40969b662cb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6327b671d74853bcbed32eda96de60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8d80c0b31c43199a13267952c14c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273b536744ed46d5b71c3b930451cc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31749606d4d240d08d67f6c3b7db9157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['resnet18_reg_stereo_2ds']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression, Stereo, PHIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type   | Params | Mode \n",
      "------------------------------------------\n",
      "0 | resnet | ResNet | 11.2 M | train\n",
      "------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.698    Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011fa3402db64515936db6be27dd9192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5731effab07c4acf8eaf7e63811abf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc7bdc6616b43518793fcf79d0a0aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf95c18eb1b644b6a4ec6f6daccd5495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9de01fa89fc4d6aa6e78f52c8de81a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be744ba12a1149b385924c14ec32350e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6dfee72bc84a2d8253adeee62751eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['resnet18_reg_stereo_phips']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification, Single View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jko/miniconda3/envs/torch/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type   | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | resnet18 | ResNet | 11.2 M | train\n",
      "--------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.695    Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b41cc2b87b8488eae4ef9cba90e4dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356f94a491a248e6ab9f19aaf1fd492a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a27eb7dc2f4ff693c1bbff1f2e85d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3926f8d96b4735a48c1359d7905134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2a19538af24f5d8f53ebcfa57f2df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0f231a0973476c973607ba91125f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc63be52fed24f8095cefe752785a3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['resnet18_cls']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification, Stereo, 2DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type   | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | resnet18 | ResNet | 11.2 M | train\n",
      "--------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.708    Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d6bc5ab57b4e6ea3320816bfbfcee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0347ca3f32b413ca80678c121d2466d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04caee0a022a4830b4b4c1f8962e8450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc63e7e52bf94c87928674c7d76a1834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98329cbff99402db7c8cb2ee11a921c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcfd7ac1ddc436fb1c6944bfd8cee0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d15ed1d0f9c4362ad5882a09534283d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['resnet18_cls_stereo_2ds']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification, Stereo, PHIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type   | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | resnet18 | ResNet | 11.2 M | train\n",
      "--------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.708    Total estimated model params size (MB)\n",
      "68        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa55e3574474d799d4db00626d6e38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadffb1ec57548388cf8012a84b21df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8514391edb4bcd8b3f8c446a3aad6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf102231c73240edadb5edf7ba44fb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c64193a0ea43a6890f0e9adeb8d4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa35cc9fbed045bb9c1f093383f58f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a6611cf8c641a58f81d1eef4c190ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# get arguments\n",
    "args = args_dict['resnet18_cls_stereo_phips']\n",
    "# Load class_to_idx mapping if provided\n",
    "class_to_idx = None\n",
    "if args.class_to_idx_json is not None:\n",
    "    with open(args.class_to_idx_json, 'r') as f:\n",
    "        class_to_idx = json.load(f)\n",
    "# Ensure log directory exists\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "tb_logger = TensorBoardLogger(args.log_dir, name=args.tb_log_name)\n",
    "csv_logger = CSVLogger(args.log_dir, name=args.csv_log_name)\n",
    "\n",
    "dm = get_datamodule(args, class_to_idx=class_to_idx)\n",
    "dm.setup()\n",
    "input_size = None\n",
    "output_size = None\n",
    "num_classes = None\n",
    "if args.model.startswith('mlp'):\n",
    "    # For tabular data, infer input/output sizes from datamodule\n",
    "    if args.data_type == 'tabular':\n",
    "        input_size = dm.input_size\n",
    "        if args.task_type == 'regression':\n",
    "            output_size = len(args.targets.split(','))\n",
    "        else:\n",
    "            num_classes = dm.num_classes\n",
    "elif args.model.endswith('classification'):\n",
    "    if class_to_idx is not None:\n",
    "        num_classes = len(class_to_idx)\n",
    "    else: # default to 7 classes\n",
    "        num_classes = 7\n",
    "elif args.model.endswith('regression'):\n",
    "    output_size = len(args.targets.split(','))\n",
    "model = get_model(args, input_size=input_size, output_size=output_size, num_classes=num_classes)\n",
    "# define checkpoint settings\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    mode='min',                 # Save checkpoints with lower val_loss\n",
    "    save_top_k=3,               # Save the 3 best models\n",
    "    filename='model-{epoch:02d}-{val_loss:.4f}',  # Custom filename\n",
    "    # every_n_epochs=1,           # Save every epoch (optional)\n",
    "    save_last=True              # Also save the last epoch\n",
    ")\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices=num_gpus,\n",
    "    logger=[csv_logger, tb_logger],\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.3 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8658764d9b797a2c8f9923ddcd38c86560d2e4c4233111378203e5da49e50175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
